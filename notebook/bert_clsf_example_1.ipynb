{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_clsf_example_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWIdScXJ0kPV",
        "outputId": "0c8de619-dea5-40d2-fc34-f327470da093"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrNOVzgv1vip"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp1kXx4Z1vg-",
        "outputId": "8196906a-d4ac-4a35-9e8f-1314b6240bbd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import cv2\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glVFnO-51vej"
      },
      "source": [
        "torch.manual_seed(777)\n",
        "random.seed(777)\n",
        "np.random.seed(777)\n",
        "\n",
        "def class_same(train_df, class_num=10000):\n",
        "  zero_df = train_df[train_df['label']==0][:class_num]\n",
        "  one_df = train_df[train_df['label']==1][:class_num]\n",
        "  total_df = pd.concat([zero_df, one_df])\n",
        "  total_df = total_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "yelp = pd.read_csv('/content/drive/My Drive/yelp.csv')\n",
        "yelp['label'] = yelp['rating']-1\n",
        "del yelp['rating']\n",
        "\n",
        "train_df = yelp[:30000]\n",
        "test_df = yelp[30000:-1000]\n",
        "val_df = yelp[-1000:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmVV2XlWL2Is",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7ad9fe-fae0-491d-a815-74401eca2d3b"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "vocab = list(tokenizer.vocab.keys())\n",
        "word_dict = dict(tokenizer.vocab.items())\n",
        "\n",
        "# 1. 모든 sentence에 CLS, SEP 붙인다.\n",
        "def get_token(text):\n",
        "    text = \"[CLS] \" + \" [SEP] \".join(sent_tokenize(text)) + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "    return tokenized_text\n",
        "\n",
        "# 2. token index로 변환, padding 한다.\n",
        "def get_ids(tokenized_text, max_length):\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    if len(indexed_tokens) < max_length:\n",
        "      input_ids = indexed_tokens + [0]*(max_length - len(indexed_tokens))\n",
        "    else:\n",
        "      input_ids = indexed_tokens[:max_length]\n",
        "    \n",
        "    return input_ids\n",
        "\n",
        "# 3. segment_ids를 만든다.\n",
        "def get_mask(input_ids):\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return attention_masks"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpzS08cJd7q7"
      },
      "source": [
        "class BERT_DATA(Dataset):\n",
        "    def __init__(self, df):\n",
        "\n",
        "        def data_setting(df, max_len):\n",
        "\n",
        "            #[CLS] [SEP] 붙임, token 변환\n",
        "            description = list(df[\"review\"])\n",
        "            descriptions = [get_token(x) for x in description]\n",
        "            description = [''.join(d) for d in descriptions]\n",
        "            #max_len\n",
        "            max_len=max_len      \n",
        "            \n",
        "            #convert Id + padding\n",
        "            input_ids = [get_ids(x,max_len) for x in descriptions]\n",
        "            \n",
        "            #Attention_masks\n",
        "            attention_masks = []\n",
        "            attention_masks = get_mask(input_ids)\n",
        "            \n",
        "            #labels\n",
        "            target = list(df['label'])\n",
        "            \n",
        "            # class수\n",
        "            num_classes=len(df['label'].unique())\n",
        "            \n",
        "            return input_ids, target,  attention_masks\n",
        "\n",
        "        input_ids, input_labels, attention_masks = data_setting(df, 512)\n",
        "\n",
        "        self.inputs = input_ids\n",
        "        self.labels = input_labels\n",
        "        self.masks = attention_masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        text = torch.tensor(self.inputs[idx])\n",
        "        label = self.labels[idx]\n",
        "        mask = torch.LongTensor(self.masks[idx])\n",
        "\n",
        "        return text, label, mask"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nGSC7g1ba-d"
      },
      "source": [
        "train_data = BERT_DATA(train_df[:1000])\n",
        "train_loader = DataLoader(train_data, batch_size=2, num_workers=2, shuffle=True)\n",
        "\n",
        "test_data = BERT_DATA(test_df)\n",
        "test_loader = DataLoader(test_data, batch_size=2, num_workers=2, shuffle=False)\n",
        "\n",
        "val_data = BERT_DATA(val_df)\n",
        "val_loader = DataLoader(val_data, batch_size=2, num_workers=2, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aApFo8vbfZ9"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, num_classes=2, hidden_size=768, dr_rate=None):\n",
        "        super(BERTClassifier,self).__init__()\n",
        "        self.bert =  bert\n",
        "        self.dr_rate = dr_rate\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1 * hidden_size, 160), # width * height * channel_num \n",
        "            nn.Linear(160, num_classes)\n",
        "        )\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def forward(self, inputs, masks):\n",
        "        with torch.no_grad():\n",
        "            encoded_layer = self.bert(inputs, masks)[1]\n",
        "\n",
        "        # encoded_layer = encoded_layer.unsqueeze(1)\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(encoded_layer)\n",
        "        x = self.classifier(out)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSXc6wdlf7ba",
        "outputId": "600044b6-69a0-4e5b-c4ef-127049a5707d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Available devices ', torch.cuda.device_count())\n",
        "\n",
        "network = BERTClassifier(model,  dr_rate=0.5).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr = 1e-3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available devices  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zjaeFbIvhLT",
        "outputId": "f4a34284-c480-4cb7-ea20-3de647909b76"
      },
      "source": [
        "network"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=160, bias=True)\n",
              "    (1): Linear(in_features=160, out_features=2, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbrAHQygxoX"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def validation(network, val_loader, device):\n",
        "\n",
        "  network.eval() \n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, (inputs, labels, masks) in enumerate(val_loader):\n",
        "          tests = inputs.to(device)\n",
        "          test_labels = labels.long().to(device)\n",
        "          masks = masks.to(device)\n",
        "\n",
        "          outputs = network(tests, masks)\n",
        "          _ , predicted = torch.max(outputs.data , 1)\n",
        "\n",
        "          total += test_labels.size(0)\n",
        "          correct += (predicted == test_labels).sum().item()\n",
        "\n",
        "      print('Test Accuracy of the model {} %'.format(100* correct/total))\n",
        "\n",
        "      return correct/total"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9SXqMmf7Qb",
        "outputId": "30712ad8-d100-4e39-ed59-481442cec043"
      },
      "source": [
        "epochs = 1\n",
        "best_acc = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "network.train()\n",
        "for e in range(epochs):\n",
        "    start_time = time.time()\n",
        "    for i, (inputs, labels, masks) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.long().to(device)\n",
        "        masks = masks.to(device)\n",
        "        outputs = network(inputs, masks)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        pred = torch.argmax(F.softmax(outputs), dim=1)\n",
        "        correct = pred.eq(labels)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 ==0:\n",
        "            print(' Epoch [{} / {}] , step [{}/ {}] Loss: {: .4f} ACC: {: .2f}'\n",
        "            .format(e +1, epochs, i+1, len(train_loader), loss.item(), total_correct/total_len))\n",
        "            total_len = 0; total_correct = 0\n",
        "\n",
        "            val_acc = validation(network, val_loader, device)\n",
        "            if best_acc < val_acc:\n",
        "              best_acc = val_acc\n",
        "              torch.save(network.state_dict(), '/content/drive/My Drive/save_model/binary_bert_model.pt')\n",
        "              print(f\"Best Model Save in {e}epoch, Validation Acc : {best_acc}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    print(f'Epoch: {e+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch [1 / 1] , step [100/ 500] Loss:  0.5755 ACC:  0.55\n",
            "Test Accuracy of the model 67.5 %\n",
            "Best Model Save in 0epoch, Validation Acc : 0.675\n",
            " Epoch [1 / 1] , step [200/ 500] Loss:  0.4649 ACC:  0.61\n",
            "Test Accuracy of the model 62.0 %\n",
            " Epoch [1 / 1] , step [300/ 500] Loss:  0.6519 ACC:  0.59\n",
            "Test Accuracy of the model 65.0 %\n",
            " Epoch [1 / 1] , step [400/ 500] Loss:  0.6990 ACC:  0.63\n",
            "Test Accuracy of the model 67.2 %\n",
            " Epoch [1 / 1] , step [500/ 500] Loss:  0.6747 ACC:  0.59\n",
            "Test Accuracy of the model 75.9 %\n",
            "Best Model Save in 0epoch, Validation Acc : 0.759\n",
            "Epoch: 01 | Epoch Time: 6m 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-gpyp33jymG",
        "outputId": "940f8377-5fa9-4262-f3eb-34ebd995f346"
      },
      "source": [
        "validation(network, test_loader, device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model 76.0 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}